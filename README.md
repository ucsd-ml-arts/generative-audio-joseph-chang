# Project 3 Generative Audio

Joseph Chang, jdchang@ucsd.edu

## Abstract

The goal of this project is to use a Performance RNN to generate MIDI music from past experience. It will take in a word as input and output music based on that word. This would require a music dataset with each piece labeled with a word. That might be complicated or hard to find. If not, could have a gansynth interpolator added so the performance RNN produces a music piece based on genre mixed with other genres to a lesser extent and the interpolator mixes the music together. This could be very useful in general to have a song DJ without an actual DJ.

Include your abstract here. This should be one paragraph clearly describing your concept, method, and results. This should tell us what architecture/approach you used. Also describe your creative goals, and whether you were successful in achieving them. Also could describe future directions.

## Model/Data

Briefly describe the files that are included with your repository:
- trained models
- training data (or link to training data)

## Code

Your code for generating your project:
- Python: generative_code.py
- Jupyter notebooks: generative_code.ipynb

## Results

Documentation of your results in an appropriate format, both links to files and a brief description of their contents:
- `.wav` files or `.mp4`
- `.midi` files
- musical scores
- ... some other form

## Technical Notes

Any implementation details or notes we need to repeat your work. 
- Does this code require other pip packages, software, etc?
- Does it run on some other (non-datahub) platform? (CoLab, etc.)

## Reference

References to any papers, techniques, repositories you used:
- Papers
- Repositories
- Blog posts
